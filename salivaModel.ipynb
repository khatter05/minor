{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd358c7a",
   "metadata": {},
   "source": [
    "# Heat Detection in Dairy cattle using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f74f5",
   "metadata": {},
   "source": [
    "### Dividing that dataset into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a2c3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1326 files [00:21, 60.54 files/s] \n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio('test/test', output=\"output1\", ratio=(.8, 0.18, 0.02)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef82ffe",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5255dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003b8a1",
   "metadata": {},
   "source": [
    "## Part-1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf76d32",
   "metadata": {},
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678106de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1060 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# in order to make sure that all the input images are of same scale, we are using ImageDataGenerator (for data augmentation)\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('output1/train/',\n",
    "                                                 target_size = (256, 256),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb1337",
   "metadata": {},
   "source": [
    "### Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2eddab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('output1/val',\n",
    "                                            target_size = (256, 256),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9b4428",
   "metadata": {},
   "source": [
    "## PART-2 Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52e5f4",
   "metadata": {},
   "source": [
    "###  Initiating the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d84e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964128bb",
   "metadata": {},
   "source": [
    "#### Step-1 Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42edf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=128,\n",
    "                               kernel_size=3,\n",
    "                               activation='relu',\n",
    "                               input_shape=[256, 256, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2992c8a1",
   "metadata": {},
   "source": [
    "#### Step-2 Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e266de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                  strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6fb707",
   "metadata": {},
   "source": [
    "### Another Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0498d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=256,\n",
    "                               kernel_size=3,\n",
    "                               activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
    "                                  strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a3e23",
   "metadata": {},
   "source": [
    "#### Step-3 Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca76650",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc43473",
   "metadata": {},
   "source": [
    "#### Step-4 Full connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=256,\n",
    "                              activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6e247",
   "metadata": {},
   "source": [
    "#### Step-5 Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28a8eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,\n",
    "                              activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e598f623",
   "metadata": {},
   "source": [
    "## Part-3 Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f99301",
   "metadata": {},
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c31f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adadelta',\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "# if we had more than 2 outcomes then we had used 'category_cross entroy'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69e234e",
   "metadata": {},
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38607a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "34/34 [==============================] - 468s 14s/step - loss: 0.6829 - accuracy: 0.5415 - val_loss: 0.6815 - val_accuracy: 0.4557\n",
      "Epoch 2/80\n",
      "34/34 [==============================] - 466s 14s/step - loss: 0.6608 - accuracy: 0.6208 - val_loss: 0.6663 - val_accuracy: 0.5738\n",
      "Epoch 3/80\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.6764 "
     ]
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5657c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "testAtypical = os.path.join('output/test/Atypical', '*')\n",
    "testAtypical = glob.glob(testAtypical)\n",
    "testTypical = os.path.join('output/test/Typical', '*')\n",
    "testTypical = glob.glob(testTypical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "for i in range(len(testAtypical)):\n",
    "    path= testAtypical[i]\n",
    "    test_image = image.load_img(path, target_size = (256, 256))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    if result[0][0] == 1:\n",
    "      prediction = 'Typical'\n",
    "    else:\n",
    "      prediction = 'Atypical'\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c4cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "for i in range(len(testTypical)):\n",
    "    path= testTypical[i]\n",
    "    test_image = image.load_img(path, target_size = (256, 256))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    training_set.class_indices\n",
    "    if result[0][0] == 1:\n",
    "      prediction = 'Typical'\n",
    "    else:\n",
    "      prediction = 'Atypical'\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2611f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('adadelta.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ade15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess(img):\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    import numpy as np\n",
    "    cnn = tf.keras.models.load_model('salivaModel.h5')\n",
    "    test_image = image.load_img(img, target_size = (256, 256))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = cnn.predict(test_image)\n",
    "    if result[0][0] == 1:\n",
    "      prediction = 'Typical'\n",
    "    else:\n",
    "      prediction = 'Atypical'\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249827b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('sample.jpeg')\n",
    "imgplot = plt.imshow(img)\n",
    "result=guess('sample.jpeg')\n",
    "print(f\"image is {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "xpoints = np.array([1, 10, 20, 30, 40, 50, 60, 70, 80])\n",
    "y1points = np.flip(np.array([86.89, 86.51, 85.28, 84.81, 84.15, 82.74, 81.6, 80.47, 56.7]))\n",
    "y2points = np.flip(np.array([80.59, 79.75, 76.79, 77.22, 78.48, 76.79, 75.11, 77.64, 54.43]))\n",
    "\n",
    "plt.plot(xpoints, y1points, label = 'accuracy')\n",
    "plt.plot(xpoints, y2points, label = 'val accuracy')\n",
    "plt.legend(loc= 4)\n",
    "plt.xlabel(\"no. of epochs \")\n",
    "plt.ylabel(\"acurracy\")\n",
    "plt.title(\"accuracy vs val. accuracy comparision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ebc02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
